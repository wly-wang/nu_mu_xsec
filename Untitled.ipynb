{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d47cd7e",
   "metadata": {},
   "source": [
    "This code is adapted from Marina's NuMI $\\nu_e$ and $\\bar{\\nu}_e$ xsec analysis for the use of a similar NuMI $\\nu_\\mu$ and $\\bar{\\nu}_\\mu$ xsec analysis. \n",
    "\n",
    "There are two stages:\n",
    "* Separate $\\nu_\\mu$ and $\\bar{\\nu}_\\mu$ by trainin a BDT, based on the BDT Marina developed for her analysis.\n",
    "* Then, individual $\\nu_\\mu$ and $\\bar{\\nu}_\\mu$ xsec will be measure using MicroBooNE off-axis NuMI beam data (run 1 and 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428a39ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================#\n",
    "#  Import Packages   #\n",
    "#====================#\n",
    "\n",
    "import math \n",
    "import numpy as np\n",
    "import awkward as ak\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "import uproot3 as uproot\n",
    "\n",
    "#Machine learning packages\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, roc_curve, roc_auc_score, accuracy_score, f1_score\n",
    "\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a30ed95",
   "metadata": {},
   "source": [
    "### Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1552448",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========================================#\n",
    "#  Define the boundaries of the TPCc volume #\n",
    "#===========================================#\n",
    "\n",
    "tpc_xmin = -1.55\n",
    "tpc_xmax = 254.8\n",
    "tpc_ymin = -115.53\n",
    "tpc_ymax = 117.47\n",
    "tpc_zmin = 0.1\n",
    "tpc_zmax = 1036.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0f9d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================#\n",
    "#  A function for creating dataframes and importing data #\n",
    "#  from root files                                       #\n",
    "#========================================================#\n",
    "def new_df(file, fType, pot_data, pot_ext, pot_mc):\n",
    "    \n",
    "    \n",
    "    #—————————————————————————————————————————————————\n",
    "    # First, define variables needed from the WC trees\n",
    "    #—————————————————————————————————————————————————\n",
    "    \n",
    "    \n",
    "    #reco vars\n",
    "    eval_vars_reco = ['flash_time', 'match_isFC']\n",
    "    pfeval_vars_reco = ['reco_nuvtxX','reco_nuvtxY', 'reco_nuvtxZ', 'run', 'subrun',\n",
    "                        'event']\n",
    "    bdt_vars_reco = ['numu_cc_flag']\n",
    "    kine_vars_reco = ['kine_reco_Enu', 'kine_pio_mass','kine_pio_flag','kine_pio_vtx_dis',\n",
    "                      'kine_pio_energy_1','kine_pio_energy_2','kine_pio_dis_1',\n",
    "                      'kine_pio_dis_2','kine_pio_angle'] #pi0 selection\n",
    "    \n",
    "    #true vars\n",
    "    kine_vars_true = []\n",
    "    bdt_vars_true = []\n",
    "    pfeval_vars_true = ['truth_corr_nuvtxX', 'truth_corr_nuvtxY', 'truth_corr_nuvtxZ', \n",
    "                        'truth_nuIntType', 'truth_pdg', 'truth_NprimPio']\n",
    "    eval_vars_true = ['weight_cv', 'weight_spline', 'truth_nuPdg', 'truth_isCC', \n",
    "                      'truth_nuEnergy','truth_vtxX', 'truth_vtxY', 'truth_vtxZ',\n",
    "                      'match_completeness_energy', 'truth_energyInside', 'truth_vtxInside']\n",
    "    \n",
    "    \n",
    "    #————————————————————————————————————\n",
    "    # import the trees from the root file\n",
    "    #————————————————————————————————————\n",
    "    \n",
    "    \n",
    "    T_eval = uproot.open(file)['wcpselection/T_eval']\n",
    "    T_PFeval = uproot.open(file)['wcpselection/T_PFeval']\n",
    "    T_BDTvars = uproot.open(file)['wcpselection/T_BDTvars']\n",
    "    T_KINEvars = uproot.open(file)['wcpselection/T_KINEvars']\n",
    "\n",
    "    \n",
    "    #———————————————————————————————————————————————————\n",
    "    # for each tree, create a reco and a true data frame\n",
    "    #———————————————————————————————————————————————————\n",
    "    \n",
    "    \n",
    "    #Reco dfs\n",
    "    df_eval_reco = T_eval.pandas.df(eval_vars_reco, flatten=False)\n",
    "    df_PFeval_reco = T_PFeval.pandas.df(pfeval_vars_reco, flatten=False)\n",
    "    df_BDTeval_reco = T_BDTvars.pandas.df(bdt_vars_reco, flatten=False)\n",
    "    df_KINEvars_reco =T_KINEvars.pandas.df(kine_vars_reco, flatten=False)\n",
    "    \n",
    "    #use concat to merge the individual reco dataframes\n",
    "    df_ = pd.concat([df_KINEvars_reco, df_BDTeval_reco, df_PFeval_reco, \n",
    "                     df_eval_reco], axis=1)\n",
    "    \n",
    "    #true dfs\n",
    "    if((fType=='MC') | (fType=='DIRT')):\n",
    "        \n",
    "        #for each tree, create a true data frame\n",
    "        df_eval_true = T_eval.pandas.df(eval_vars_true, flatten=False)\n",
    "        df_PFeval_true = T_PFeval.pandas.df(pfeval_vars_true, flatten=False)\n",
    "        df_BDTeval_true = T_BDTvars.pandas.df(bdt_vars_true, flatten=False)\n",
    "        df_KINEvars_true =T_KINEvars.pandas.df(kine_vars_true, flatten=False)\n",
    "        \n",
    "        #use concat to merge the individual dataframes\n",
    "        df_ = pd.concat([df_, df_KINEvars_true, df_BDTeval_true, df_PFeval_true, \n",
    "                         df_eval_true], axis=1)\n",
    "        \n",
    "        #fix vars, make sure they have reasonable values (weight_cv & weight_spline)\n",
    "        df_['weight_cv'] = np.where((df_.weight_cv <= 0), 1, df_.weight_cv)\n",
    "        df_['weight_cv'] = np.where((df_.weight_cv > 30), 1, df_.weight_cv)\n",
    "        df_['weight_cv'] = np.where((df_.weight_cv == np.nan), 1, df_.weight_cv)\n",
    "        df_['weight_cv'] = np.where((df_.weight_cv == np.inf), 1, df_.weight_cv)\n",
    "        df_['weight_cv'] = np.where((df_['weight_cv'].isna()), 1, df_.weight_cv)\n",
    "        df_['weight_spline'] = np.where((df_.weight_spline <= 0), 1, df_.weight_spline)\n",
    "        df_['weight_spline'] = np.where((df_.weight_spline > 30), 1, df_.weight_spline)\n",
    "        df_['weight_spline'] = np.where((df_.weight_spline == np.nan), 1, df_.weight_spline)\n",
    "        df_['weight_spline'] = np.where((df_.weight_spline == np.inf), 1, df_.weight_spline)\n",
    "        df_['weight_spline'] = np.where((df_['weight_spline'].isna()), 1, df_.weight_spline)\n",
    "        \n",
    "    \n",
    "    #————————————————\n",
    "    # only impose FHC\n",
    "    #————————————————\n",
    "    \n",
    "    \n",
    "    df_ = df_[df_.run<6748]\n",
    "    \n",
    "    \n",
    "    #————————————————————————\n",
    "    # calculate event weights\n",
    "    #————————————————————————\n",
    "    \n",
    "    \n",
    "    if((fType=='MC') | (fType=='DIRT')):\n",
    "        W_ = pot_data/pot_mc\n",
    "        df_.loc[:,'weight_genie'] = df_['weight_cv'] * df_['weight_spline']\n",
    "        df_.loc[:,'weight_ubtune'] = [W_]*df_.shape[0] * df_['weight_genie']\n",
    "        df_.loc[:,'weight_no_ubtune'] = [W_]*df_.shape[0] * df_['weight_spline']\n",
    "    elif(fType=='DATA'): #for beam-on sample\n",
    "        W_ = 1\n",
    "        df_.loc[:,'weight_ubtune'] = [W_]*df_.shape[0]\n",
    "    elif(fType=='EXT'): #for beam-off sample\n",
    "        W_ = (pot_data/pot_mc)*0.98\n",
    "        df_.loc[:,'weight_ubtune'] = [W_]*df_.shape[0]\n",
    "        \n",
    "    \n",
    "    #————————————————————————————————————————————\n",
    "    # For beam-on/off data, apply a quality check\n",
    "    #————————————————————————————————————————————\n",
    "    \n",
    "    \n",
    "    if((fType=='DATA') | (fType=='EXT')):\n",
    "        df_good_runs = pd.read_csv('run1_beamon_goodquality.list', \n",
    "                sep=\", \", header=None, engine='python')\n",
    "        df_good_runs = df_good_runs.T\n",
    "        df_good_runs.rename(columns={0:'run'}, inplace=True)\n",
    "        list_good_runs = df_good_runs['run'].values.tolist()\n",
    "        df_ = df_[df_['run'].isin(list_good_runs)]\n",
    "        \n",
    "        \n",
    "    \n",
    "    #—————————————————————————————————————————————————————————————————\n",
    "    # fix neutrino energy for data\n",
    "    # the neutrino reconstructed energy needs to be corrected for data\n",
    "    # tot_energy = shower_energy + track_energy\n",
    "    # and the shower_energy needs a 95% correction factor\n",
    "    #————————————————————————————————————————————————————————————————— \n",
    "    \n",
    "    \n",
    "    if(fType=='DATA'):\n",
    "        def get_data_nuEnergyCorrected(df_, file):\n",
    "            \n",
    "            df_in = df_.copy()\n",
    "\n",
    "            # create dataframe with relevant information to \n",
    "            # calculate DATA neutrino energy\n",
    "            tree = uproot.open(file)['wcpselection/T_KINEvars']\n",
    "            var = ['kine_energy_particle', 'kine_energy_info', 'kine_particle_type', \n",
    "                   'kine_reco_add_energy', 'kine_reco_Enu']\n",
    "            df_temp = tree.pandas.df(var, flatten = True)\n",
    "\n",
    "            # apply cuts and define new dataframes\n",
    "            df_temp = df_temp[ df_temp.kine_reco_Enu>0 ]\n",
    "            df_EM = df_temp[ (df_temp.kine_energy_info==2) \\\n",
    "                            & (df_temp.kine_particle_type==11) ] # shower\n",
    "            df_track = df_temp[ (df_temp.kine_energy_info!=2) \\\n",
    "                               | (df_temp.kine_particle_type!=11) ] # track\n",
    "\n",
    "            # apply 95% correction on EM\n",
    "            df_EM.loc[:,'kine_energy_particle'] = df_EM['kine_energy_particle']\\\n",
    "                                                .apply(lambda x: x*0.95)\n",
    "\n",
    "            df_temp.loc[:,'energy_EM'] = df_EM.groupby(['entry'])['kine_energy_particle']\\\n",
    "                                        .transform('sum')\n",
    "            df_temp.loc[:,'energy_track'] = df_track.groupby(['entry'])\\\n",
    "                                        ['kine_energy_particle'].transform('sum')\n",
    "\n",
    "            df_temp['energy_EM'].fillna(0, inplace=True)\n",
    "            df_temp['energy_track'].fillna(0, inplace=True)\n",
    "\n",
    "            df_temp['energy_EM'] = df_temp.groupby(['entry'])['energy_EM'].transform(max)\n",
    "            df_temp['energy_track'] = df_temp.groupby(['entry'])['energy_track']\\\n",
    "                                        .transform(max)\n",
    "\n",
    "            df_temp = df_temp.groupby('entry').first()\n",
    "\n",
    "            df_temp['kine_reco_Enu_corr'] = df_temp['energy_EM'] + df_temp['energy_track'] \\\n",
    "                                            + df_temp['kine_reco_add_energy']\n",
    "            df_temp = df_temp.drop(['kine_energy_particle','kine_energy_info',\n",
    "                                    'kine_particle_type','kine_reco_add_energy',\n",
    "                                    'kine_reco_Enu','energy_EM','energy_track'], axis=1)\n",
    "            df_temp = df_temp.rename(columns={\"kine_reco_Enu_corr\":\"kine_reco_Enu\"})\n",
    "\n",
    "            df_in.update(df_temp)\n",
    "            return df_in\n",
    "\n",
    "            df_ = get_data_nuEnergyCorrected(df_.copy(),File)\n",
    "    \n",
    "    \n",
    "    #—————————————\n",
    "    # add RSE info\n",
    "    #—————————————\n",
    "    \n",
    "    \n",
    "    df_['RSE'] = df_[\"run\"].astype(int).apply(str) + \"_\" \\\n",
    "                + df_[\"subrun\"].astype(int).apply(str) + \"_\" \\\n",
    "                + df_[\"event\"].astype(int).apply(str)\n",
    "    \n",
    "    \n",
    "    #——————————————————————\n",
    "    # Print POT and Entries\n",
    "    #——————————————————————\n",
    "    \n",
    "    \n",
    "    if((fType=='MC') | (fType=='DIRT')):\n",
    "        print('[%s] POT %5.2e      %7i entries' % (fType,pot_mc,len(df_)))\n",
    "    elif(fType=='DATA'): #for beam-on sample\n",
    "        print('[%s] POT %5.2e      %7i entries' % (fType,pot_data,len(df_)))\n",
    "    elif(fType=='EXT'): #for beam-off sample (TBC the pot calc)\n",
    "        print('[%s] POT %5.2e      %7i entries' % (fType,pot_ext,len(df_)))\n",
    "        \n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2f0807",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================#\n",
    "#  A Function used to create pot  #\n",
    "#=================================#\n",
    "def calc_pot(file, fType):\n",
    "    \n",
    "    \n",
    "    #—————————————————————\n",
    "    #create necessary vars\n",
    "    #—————————————————————\n",
    "    \n",
    "    \n",
    "    if(fType=='MC'):\n",
    "        pot_vars = ['runNo','pot_tor875']\n",
    "    elif(fType=='DIRT'):\n",
    "        pot_vars = ['run','pot_tor875']\n",
    "    \n",
    "    \n",
    "    #——————————————————————————————————————\n",
    "    #import the pot tree from the root file\n",
    "    #——————————————————————————————————————\n",
    "    \n",
    "    \n",
    "    T_pot = uproot.open(file)['wcpselection/T_pot']\n",
    "    \n",
    "    \n",
    "    #———————————————————————————\n",
    "    #Create a pd df for pot tree\n",
    "    #———————————————————————————\n",
    "    \n",
    "    \n",
    "    df_pot = T_pot.pandas.df(pot_vars, flatten=False)\n",
    "    \n",
    "    #only impose FHC\n",
    "    if(fType=='MC'):\n",
    "        df_pot = df_pot[df_pot.runNo<6748]\n",
    "    elif(fType=='DIRT'):\n",
    "        df_pot = df_pot[df_pot.run<6748]\n",
    "    \n",
    "    \n",
    "    #—————————————————\n",
    "    #Calculate the pot\n",
    "    #—————————————————\n",
    "    \n",
    "    \n",
    "    pot = sum(df_pot.pot_tor875)\n",
    "    return pot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4b987f",
   "metadata": {},
   "source": [
    "### Event Selection Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dd5a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===============================================================#\n",
    "# A Function for clearing non-physical values for reco vertices #\n",
    "#===============================================================#\n",
    "\n",
    "\n",
    "def reco_nu_vtx_val_clearing(df):\n",
    "    df_ = df.query('reco_nuvtxX != -1 & reco_nuvtxY != -1 & reco_nuvtxZ != -1')\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6c8404",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=======================================================#\n",
    "#  A Function for Generic Neutrino Selection and NumuCC #\n",
    "#=======================================================#\n",
    "\n",
    "\n",
    "def gen_nu_selec(df):\n",
    "    selec_df = df[df.numu_cc_flag >= 1]\n",
    "    return selec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64bf520",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========================================#\n",
    "#  A Function for Fiducial Volume Selection #\n",
    "#===========================================#\n",
    "\n",
    "\n",
    "def apply_inFV(df):\n",
    "    dist = 3 # distance from the boundaries\n",
    "    df_ = df[((df.reco_nuvtxX>(tpc_xmin+dist)) & (df.reco_nuvtxX<(tpc_xmax-dist))) &\n",
    "             ((df.reco_nuvtxY>(tpc_ymin+dist)) & (df.reco_nuvtxY<(tpc_ymax-dist))) & \n",
    "             ((df.reco_nuvtxZ>(tpc_zmin+dist)) & (df.reco_nuvtxZ<(tpc_zmax-dist)))]    \n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20656a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=========================================================#\n",
    "#  A Function for Containment Selection (Fully contained) #\n",
    "#=========================================================#\n",
    "\n",
    "\n",
    "def apply_isFC(df):\n",
    "    selec_df = df[df.match_isFC==1]\n",
    "    return selec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eafce1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#============================================================#\n",
    "# A Function for Containment Selection (Partially contained) #\n",
    "#============================================================#\n",
    "\n",
    "\n",
    "def apply_notFC(df):\n",
    "    selec_df = df[df.match_isFC==0]\n",
    "    return selec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b234b646",
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================#\n",
    "# A Function for applying selection cuts #\n",
    "#========================================#\n",
    "\n",
    "\n",
    "def applyCuts(label, dfData, dfEXT, dfOverlay, print_lengths, POT_data):\n",
    "    print('\\n---------- Applying: %s\\n' % label)\n",
    "\n",
    "\n",
    "    #—————————————#\n",
    "    # Apply cuts  #\n",
    "    #—————————————#\n",
    "\n",
    "\n",
    "    if (label=='None'):                 # No selection applied\n",
    "        df_data = dfData\n",
    "        df_mc = dfOverlay\n",
    "        df_ext = dfEXT\n",
    "    elif (label=='recoVtxTrim'):         # Trim down badly reconstructed vertex values\n",
    "        df_data = reco_nu_vtx_val_clearing(dfData)\n",
    "        df_mc = reco_nu_vtx_val_clearing(dfOverlay)\n",
    "        df_ext = reco_nu_vtx_val_clearing(dfEXT)\n",
    "    elif (label=='genNuSelection'):      # Generic Neutrino Selection and numuCC selection\n",
    "        df_data = gen_nu_selec(dfData)\n",
    "        df_mc = gen_nu_selec(dfOverlay)\n",
    "        df_ext = gen_nu_selec(dfEXT)\n",
    "    elif (label=='fiducialVol'):         # Fiducial volume selection\n",
    "        df_data = apply_inFV(dfData)\n",
    "        df_mc = apply_inFV(dfOverlay)\n",
    "        df_ext = apply_inFV(dfEXT)\n",
    "\n",
    "    if(print_lengths==True):\n",
    "        print('[DATA] %7i entries' % len(df_data))\n",
    "        print('[EXT]  %7i entries' % len(df_ext))\n",
    "        print('[MC]   %7i entries' % len(df_mc))\n",
    "\n",
    "    # make stacked histograms\n",
    "    plots_for_SelectionCuts(df_data, df_ext, df_mc, label, POT_data)\n",
    "        \n",
    "    # return the updated dataframes\n",
    "    return df_data, df_ext, df_mc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a4f157",
   "metadata": {},
   "source": [
    "### MC Topology Classification Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c7821b-362b-428f-816e-bb81787e776c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isCosmic(df):\n",
    "    df_ = df[((df.match_completeness_energy <= df.truth_energyInside * 0.1) \\\n",
    "               | (df.truth_energyInside <= 0))]\n",
    "    # print('Number of rows BEFORE query: %s' % len(df))\n",
    "    # df_ = df.query('match_completeness_energy <= truth_energyInside*0.1 \\\n",
    "    #                       | truth_energyInside <= 0')\n",
    "    # print('Number of rows AFTER query: %s' % len(df_))\n",
    "    return df_\n",
    "\n",
    "def notCosmic(df):\n",
    "    df_ = df[((df.match_completeness_energy > df.truth_energyInside * 0.1) \\\n",
    "               & (df.truth_energyInside > 0))]\n",
    "    # print('Number of rows BEFORE query: %s' % len(df))\n",
    "    # df_ = df.query('match_completeness_energy > truth_energyInside*0.1 \\\n",
    "    #                & truth_energyInside > 0')\n",
    "    # print('Number of rows AFTER query: %s' % len(df_))\n",
    "    return df_\n",
    "\n",
    "def isOutFV(df):\n",
    "    df_ = df[(df.truth_vtxInside==0)]  \n",
    "    # print('Number of rows BEFORE query: %s' % len(df))\n",
    "    # df_ = df.query('truth_vtxInside==0')                          # vtx outFV\n",
    "    # print('Number of rows AFTER query: %s' % len(df_))\n",
    "    return df_\n",
    "\n",
    "def isNue_NuebarCC(df):\n",
    "    df_ = df[((df.truth_nuPdg==12) | (df.truth_nuPdg==-12))    \n",
    "             & (df.truth_isCC==1)] \n",
    "    # df_ = df.query('truth_nuPdg==12 | truth_nuPdg==-12')                            # nue/nue_barCC\n",
    "    return df_\n",
    "\n",
    "def isNumuCC(df):\n",
    "    df_ = df[(df.truth_nuPdg==14) &                             \n",
    "             (df.truth_isCC==1)] \n",
    "    # df_ = df.query('truth_nuPdg==14 & \\\n",
    "    #                truth_isCC==1')                               # numu CC\n",
    "    return df_\n",
    "\n",
    "def isNumu_barCC(df):\n",
    "    # df_ = df[(df.truth_nuPdg==-14) &                             \n",
    "    #          (df.truth_isCC==1)]  \n",
    "    df_ = df.query('truth_nuPdg==-14 & \\\n",
    "                   truth_isCC==1')                               # numu_barCC\n",
    "    return df_\n",
    "\n",
    "def isNCpi(df):\n",
    "    mask_pi = np.array([211 in array for array in np.abs(np.int32(np.array(df.truth_pdg)))])\n",
    "    mask_isNC = df.truth_isCC==0                                 # NC with charged pions\n",
    "    df_ = df[mask_isNC & mask_pi]\n",
    "    #df_ = df.query('(truth_pdg==211 | truth_pdg==-211) & truth_isCC==0')\n",
    "    return df_\n",
    "\n",
    "def isNC(df):\n",
    "    mask_no_pi = np.array([not 211 in array for array in np.abs(np.int32(np.array(df.truth_pdg)))])\n",
    "    mask_isNC = df.truth_isCC==0\n",
    "    df_ = df[mask_isNC & mask_no_pi]                             # NC with no pions\n",
    "    # df_ = df.query('(truth_pdg!=211 | truth_pdg!=-211) & truth_isCC==0')\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaf661c-9ba3-4c5f-984c-ef61b0f3b2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#—————————————————————\n",
    "#Test cell for mask_pi\n",
    "#—————————————————————\n",
    "\n",
    "# #criterion = []\n",
    "# for idx, subarray in enumerate(test_df[\"truth_pdg\"]):\n",
    "#     criterion.append(int((211) in np.abs(subarray)))\n",
    "\n",
    "# print(f\"Number of entries: {test_df['truth_pdg'].count()}\")\n",
    "# print(f\"Entries with 211: {sum(criterion)}\")\n",
    "# print('Number of NC: %s' % test_nc['truth_pdg'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5729120",
   "metadata": {},
   "source": [
    "### Funtions for Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c132fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=============================================#\n",
    "#  Functions setting vars to plot after cuts  #\n",
    "#=============================================#\n",
    "\n",
    "\n",
    "def plots_for_SelectionCuts(df_data, df_ext, df_overlay, label, POT_data):\n",
    "    \n",
    "    # this function makes all the plots that you want to plot throughout the pre-selection cuts\n",
    "    \n",
    "    # --- MC/DATA comparison\n",
    "    mc_data_stacked_hist(df_data, df_ext, df_overlay, \"reco_nuvtxX\", \\\n",
    "                            \"plots/%s_nuvtxX\" % label, \"Reco neutrino Vertex X [cm]\", \\\n",
    "                            tpc_xmin, tpc_xmax, 25, POT_data)\n",
    "    mc_data_stacked_hist(df_data, df_ext, df_overlay, \"reco_nuvtxY\", \\\n",
    "                            \"plots/%s_nuvtxY\" % label, \"Reco neutrino Vertex Y [cm]\", \\\n",
    "                            tpc_ymin, tpc_ymax, 25, POT_data)\n",
    "    mc_data_stacked_hist(df_data, df_ext, df_overlay, \"reco_nuvtxZ\", \\\n",
    "                            \"plots/%s_nuvtxZ\" % label, \"Reco neutrino Vertex Z [cm]\", \\\n",
    "                            tpc_zmin, tpc_zmax, 25, POT_data)\n",
    "    \n",
    "    mc_data_stacked_hist(df_data, df_ext, df_overlay, \"flash_time\", \\\n",
    "                            \"plots/%s_flash_time\" % label, r\"Flash Time [$\\mu$s]\", \\\n",
    "                            4, 18, 50, POT_data)\n",
    "    \n",
    "    mc_data_stacked_hist(df_data, df_ext, df_overlay, \"kine_reco_Enu\", \\\n",
    "                            \"plots/%s_kine_reco_Enu\" % label, \"Reco Neutrino Energy [MeV]\",\\\n",
    "                            0, 1600, 30, POT_data)\n",
    "    \n",
    "    mc_data_stacked_hist(df_data, df_ext, df_overlay, \"numu_cc_flag\", \\\n",
    "                            \"plots/%s_numu_cc_flag\" % label, r\"$\\nu_{\\mu}$ CC Score (AU)\",\\\n",
    "                            -1, 1, 10, POT_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1bf039-7bed-43a1-be53-ff872760634d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=============================================#\n",
    "#  A Function for Plotting Stacked Histograms #\n",
    "#=============================================#\n",
    "\n",
    "\n",
    "def mc_data_stacked_hist(df_data, df_ext, df_mc, var, plot_png_name, xaxis, xmin, \\\n",
    "                         xmax, nbins, pot_data):\n",
    "    #————————————————————————————————————————————————#\n",
    "    # Restrict the range of df in the plotting range #\n",
    "    #————————————————————————————————————————————————#\n",
    "    \n",
    "    \n",
    "    # df_data = df_data[(df_data[var]>=xmin) & (df_data[var]<=xmax)]\n",
    "    # df_ext = df_ext[(df_ext[var]>=xmin) & (df_ext[var]<=xmax)]\n",
    "    # df_mc = df_mc[(df_mc[var]>=xmin) & (df_mc[var]<=xmax)]\n",
    "    \n",
    "    \n",
    "    #————————————————————————————————————————————#\n",
    "    # Get the number of entries for each dataset #\n",
    "    #————————————————————————————————————————————#\n",
    "    \n",
    "    \n",
    "    n_data = len(df_data)\n",
    "    n_ext = len(df_ext)\n",
    "    n_mc = len(df_mc)\n",
    "    \n",
    "    \n",
    "    #———————————————————————————————————#\n",
    "    # Classify mc df into each topology #\n",
    "    #———————————————————————————————————#\n",
    "    \n",
    "    \n",
    "    # cosmic\n",
    "    df_cosmic = isCosmic(df_mc)\n",
    "    n_cosmic = len(df_cosmic)\n",
    "    # df_mc = pd.concat([df_mc, df_cosmic, df_cosmic], axis=0).drop_duplicates()\n",
    "\n",
    "    # outFV\n",
    "    df_outFV = isOutFV(df_mc)\n",
    "    n_outFV = len(df_outFV)\n",
    "    # df_mc = pd.concat([df_mc, df_outFV, df_outFV], axis=0).drop_duplicates(keep=False)\n",
    "\n",
    "    # numuCC\n",
    "    df_numuCC = isNumuCC(df_mc)\n",
    "    n_numuCC = len(df_numuCC)\n",
    "\n",
    "    # numubarCC\n",
    "    df_numu_barCC = isNumu_barCC(df_mc)\n",
    "    n_numu_barCC = len(df_numu_barCC)\n",
    "\n",
    "    # NCpi+,-\n",
    "    df_ncpi = isNCpi(df_mc)\n",
    "    n_ncpi = len(df_ncpi)\n",
    "\n",
    "    # NC\n",
    "    df_nc = isNC(df_mc)\n",
    "    n_nc = len(df_nc)\n",
    "    \n",
    "    # nue and nuebarCC\n",
    "    df_nue_nuebarCC = isNue_NuebarCC(df_mc)\n",
    "    n_nue_nuebarCC = len(df_nue_nuebarCC)\n",
    "\n",
    "    print('\\nOverlay (%i entries)' % n_mc)\n",
    "    print('Cosmic    %10i' % n_cosmic)\n",
    "    print('outFV     %10i \\n' % n_outFV)\n",
    "    print('NumuCC %10i' % n_numuCC)\n",
    "    print('NumubarCC    %10i' % n_numu_barCC)\n",
    "    print('NCpi      %10i' % n_ncpi)\n",
    "    print('NC        %10i' % n_nc)\n",
    "    print('Nue/NuebarCC %10i' % n_nue_nuebarCC)\n",
    "    print('Total     %10i' % (n_numuCC + n_numu_barCC \\\n",
    "                              + n_ncpi + n_nc + n_nue_nuebarCC))\n",
    "    \n",
    "    \n",
    "    #—————————————#\n",
    "    # get entries #\n",
    "    #—————————————#\n",
    "    \n",
    "    \n",
    "    hist_list = [df_cosmic[var],\n",
    "                 df_outFV[var],\n",
    "                 df_numuCC[var],\n",
    "                 df_numu_barCC[var],\n",
    "                 df_nc[var],\n",
    "                 df_ncpi[var],\n",
    "                 df_nue_nuebarCC[var],\n",
    "                 df_ext[var]]\n",
    "    \n",
    "    hist_data = df_data[var]\n",
    "    \n",
    "    \n",
    "    #—————————————#\n",
    "    # Colors!!!!! #\n",
    "    #—————————————#\n",
    "    \n",
    "    \n",
    "    c_list = ['paleturquoise',\n",
    "              'springgreen',\n",
    "              'limegreen',\n",
    "              'aqua',\n",
    "              'orange',\n",
    "              'saddlebrown',\n",
    "              'grey',\n",
    "              'gold']\n",
    "\n",
    "    c_data = 'black'\n",
    "    \n",
    "    \n",
    "    #————————#\n",
    "    # labels #\n",
    "    #————————#\n",
    "    \n",
    "    \n",
    "    label_list = ['Cosmic',\n",
    "                  'outFV',\n",
    "                  r'$\\nu_{\\mu}$ CC',\n",
    "                  r'$\\bar{\\nu}_{\\mu}$ CC',\n",
    "                  'NC',\n",
    "                  r'NC $\\pi$',\n",
    "                  r'$\\nu_{e}$ CC',\n",
    "                  'EXT']\n",
    "\n",
    "    label_data = 'Data'\n",
    "    \n",
    "    \n",
    "    #——————————————————————#\n",
    "    # Create Stacked Histo #\n",
    "    #——————————————————————#\n",
    "    \n",
    "    \n",
    "    xrange = (xmin ,xmax)\n",
    "    hist_stacked, bins_stacked, counts_stacked = plt.hist(hist_list, bins=nbins, \\\n",
    "                                                            range=(xmin,xmax),\\\n",
    "                                                             color=c_list, \\\n",
    "                                                            label=label_list,\\\n",
    "                                                            stacked=True)     \n",
    "    data_hist, bins_ = np.histogram(hist_data, bins=nbins, range=xrange)\n",
    "    err_bar = [np.sqrt(x) for x in data_hist]\n",
    "    mid = 0.5*(bins_[1:] + bins_[:-1])\n",
    "    plt.errorbar(mid, data_hist, xerr=0.5*xrange[1]/nbins, yerr=err_bar, color=c_data, label=label_data, fmt='o')   \n",
    "    \n",
    "    #plt.yscale('log')\n",
    "    plt.legend(loc='best', ncol=2, prop={'size': 8})\n",
    "    plt.ylabel('Entries')\n",
    "    plt.xlabel('%s' % xaxis)\n",
    "    plt.title(r'MicroBooNE NuMI Data: %1.1e POT' % pot_data, loc='left')\n",
    "\n",
    "    #make space for the legend\n",
    "    max_data = data_hist.max()\n",
    "    max_mc = hist_stacked.max()\n",
    "    max_all = 0\n",
    "    if(max_data>max_mc): max_all = max_data\n",
    "    else: max_all = max_mc\n",
    "    plt.ylim((0,max_all*1.2))\n",
    "\n",
    "\n",
    "    plt.savefig('%s.pdf' % plot_png_name)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    '''\n",
    "    #—————————————#\n",
    "    # get weights #\n",
    "    #—————————————#\n",
    "    \n",
    "    \n",
    "    w_list = [df_cosmic[weight],\n",
    "              df_outFV[weight],\n",
    "              df_numuCC[weight],\n",
    "              df_numuCCpi0[weight],\n",
    "              df_nc[weight],\n",
    "              df_ncpi0[weight],\n",
    "              df_nuebarCC[weight],\n",
    "              df_nueCC[weight],\n",
    "              df_ext[weight]]\n",
    "    \n",
    "    w_data = df_data[weight]\n",
    "\n",
    "    \n",
    "    #—————————————#\n",
    "    # Colors!!!!! #\n",
    "    #—————————————#\n",
    "    \n",
    "    \n",
    "    c_list = ['paleturquoise',\n",
    "              'springgreen',\n",
    "              'limegreen',\n",
    "              'aqua',\n",
    "              'orange',\n",
    "              'saddlebrown',\n",
    "              'grey',\n",
    "              'brown',\n",
    "              'gold']\n",
    "\n",
    "    c_data = 'black'\n",
    "    \n",
    "    \n",
    "    #————————#\n",
    "    # labels #\n",
    "    #————————#\n",
    "    \n",
    "    \n",
    "    label_list = ['Cosmic',\n",
    "                  'outFV',\n",
    "                  r'$\\nu_{\\mu}$ CC $\\pi^{0}$',\n",
    "                  r'$\\nu_{\\mu}$ CC',\n",
    "                  r'NC $\\pi^{0}$',\n",
    "                  'NC',\n",
    "                  r'$\\nu_{e}$ CC',\n",
    "                  r'$\\bar{\\nu}_{e}$ CC',\n",
    "                  'EXT']\n",
    "\n",
    "    label_data = 'Data'\n",
    "    \n",
    "    \n",
    "    #——————————————————————#\n",
    "    # Create Stacked Histo #\n",
    "    #——————————————————————#\n",
    "    \n",
    "    \n",
    "    legend_size = 12\n",
    "    xrange = (xmin ,xmax) \n",
    "    axis_label_size = 18\n",
    "    ticks_size = 14\n",
    "\n",
    "    # configure the canvas\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(10,10), gridspec_kw=dict(height_ratios=[4,1]), \\\n",
    "                            sharex=True)\n",
    "    plt.subplots_adjust(left=0.125,\n",
    "                        bottom=0.1, \n",
    "                        right=0.9, \n",
    "                        top=0.9, # position of top part of the top pad\n",
    "                        wspace=0.2, \n",
    "                        hspace=0.1) # distance between plots\n",
    "    \n",
    "    # plot stacked histogram\n",
    "    hist_stacked, bins_stacked, counts_stacked = axs[0].hist(hist_list, bins=nbins, \\\n",
    "                                                            range=(xmin,xmax),\\\n",
    "                                                             color=c_list, \\\n",
    "                                                            stacked=True)     \n",
    "    data_hist, bins_ = np.histogram(hist_data, bins=nbins, range=xrange)\n",
    "    err_bar = [np.sqrt(x) for x in data_hist]\n",
    "    mid = 0.5*(bins_[1:] + bins_[:-1])\n",
    "    axs[0].errorbar(mid, data_hist, xerr=0.5*xrange[1]/nbins, yerr=err_bar, color=c_data, \\\n",
    "                     fmt='o')   \n",
    "    \n",
    "    # get the histograms individually\n",
    "    hist8 = axs[1].hist(hist_list[8], bins=nbins, range=xrange, \\\n",
    "                        color=c_list[8], label=label_list[8], stacked=True) # EXT\n",
    "    hist7 = axs[1].hist(hist_list[7], bins=nbins, range=xrange, \\\n",
    "                        color=c_list[7], label=label_list[7], stacked=True) # nuebarCC\n",
    "    hist6 = axs[1].hist(hist_list[6], bins=nbins, range=xrange, \\\n",
    "                        color=c_list[6], label=label_list[6], stacked=True) # nueCC\n",
    "    hist5 = axs[1].hist(hist_list[5], bins=nbins, range=xrange, \\\n",
    "                        color=c_list[5], label=label_list[5], stacked=True) # NC\n",
    "    hist4 = axs[1].hist(hist_list[4], bins=nbins, range=xrange, \\\n",
    "                        color=c_list[4], label=label_list[4], stacked=True) # NCpi0\n",
    "    hist3 = axs[1].hist(hist_list[3], bins=nbins, range=xrange, \\\n",
    "                        color=c_list[3], label=label_list[3], stacked=True) # numuCC\n",
    "    hist2 = axs[1].hist(hist_list[2], bins=nbins, range=xrange, \\\n",
    "                        color=c_list[2], label=label_list[2], stacked=True) # numuCCpi0\n",
    "    hist1 = axs[1].hist(hist_list[1], bins=nbins, range=xrange, \\\n",
    "                        color=c_list[1], label=label_list[1], stacked=True) # outFV\n",
    "    hist0 = axs[1].hist(hist_list[0], bins=nbins, range=xrange, \\\n",
    "                        color=c_list[0], label=label_list[0], stacked=True) # cosmic\n",
    "    axs[1].clear() # clear the axis so we can simply plot the ratio\n",
    "    \n",
    "    \n",
    "    #———————————————————————#\n",
    "    # Styling for the histo #\n",
    "    #———————————————————————#\n",
    "    \n",
    "    \n",
    "    axs[0].set_ylim(bottom=0)\n",
    "    axs[0].legend(loc='best', ncol=3, prop={'size': 12})\n",
    "    axs[0].set_ylabel('Entries', size=axis_label_size, loc='top')\n",
    "    axs[0].set_title(r'MicroBooNE NuMI Data: %1.1e POT' % pot_data, size=20, loc='left')\n",
    "    axs[0].yaxis.set_tick_params(labelsize=ticks_size)\n",
    "    axs[0].set_xlabel('%s' % xaxis, size=axis_label_size)\n",
    "    axs[0].xaxis.set_tick_params(labelsize=ticks_size)\n",
    "    axs[0].set_ylim([0.9, 1.1])\n",
    "    \n",
    "    # find the maximum to make space for the legend (multiply max by 1.5)\n",
    "    max_data = np.max(data_total)\n",
    "    max_mc = np.max(mc_total)\n",
    "    max_all = 0\n",
    "    if(max_data>max_mc): max_all = max_data\n",
    "    else: max_all = max_mc\n",
    "    axs[0].set_ylim((0,max_all*1.5))\n",
    "    '''\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee261d0",
   "metadata": {},
   "source": [
    "### ACTUAL CODE EXECUTION\n",
    "\n",
    "First Get the files and create the dataframes for the NTuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d98d8e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#——————————————————————————————————————\n",
    "#  Get the files needed and their dir  \n",
    "#——————————————————————————————————————\n",
    "file_mc = 'ROOT_files/checkout_prodgenie_numi_overlay_CV_run1.root'\n",
    "file_beam_on = 'ROOT_files/checkout_prodgenie_numi_beamon_run1.root'\n",
    "file_dirt = 'ROOT_files/run1_dirt.root'\n",
    "file_ext = 'ROOT_files/checkout_data_extnumi_run1.root'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd1d6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#——————————————————————————————\n",
    "#Calculate pot for each dataset\n",
    "#——————————————————————————————\n",
    "    \n",
    "\n",
    "#From the run1 beam-on good quality file\n",
    "run1_tortgt_wcut = 2.014e+20\n",
    "run1_EA9CNT_wcut = 5304302.0\n",
    "\n",
    "#EXT info\n",
    "run1_EXT_NUMIwin_FEMBeamTriggerAlgo = 2466466.930000\n",
    "\n",
    "#calculate pot for datasets\n",
    "run1_pot_beam_on = run1_tortgt_wcut\n",
    "run1_pot_ext = run1_pot_beam_on/(run1_EA9CNT_wcut/run1_EXT_NUMIwin_FEMBeamTriggerAlgo)\n",
    "run1_pot_mc = calc_pot(file_mc, 'MC')\n",
    "run1_pot_dirt = calc_pot(file_dirt, 'DIRT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995e48f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#—————————————————————————————————————\n",
    "# Create dataframes containing NTuples \n",
    "#—————————————————————————————————————\n",
    "\n",
    "\n",
    "lock1 = True\n",
    "if lock1==True:    \n",
    "    \n",
    "    df_mc = new_df(file_mc, 'MC', run1_pot_beam_on, run1_pot_ext, run1_pot_mc)\n",
    "    df_beam_on = new_df(file_beam_on, 'DATA', run1_pot_beam_on, run1_pot_ext, run1_pot_mc)\n",
    "    df_ext = new_df(file_ext, 'EXT', run1_pot_beam_on, run1_pot_ext, run1_pot_mc)\n",
    "    df_dirt = new_df(file_dirt, 'DIRT', run1_pot_beam_on, run1_pot_ext, run1_pot_mc)\n",
    "    print('\\nDataframes created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5974764f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#—————————————————————————————————————\n",
    "# Save Dataframe for fast code running \n",
    "#—————————————————————————————————————\n",
    "\n",
    "lock2 = False\n",
    "if lock2==True:  \n",
    "    df_mc.to_csv('dfs/df_run1_mc.csv')\n",
    "    df_beam_on.to_csv('dfs/df_run1_data.csv')\n",
    "    df_dirt.to_csv('dfs/df_run1_dirt.csv')\n",
    "    df_ext.to_csv('dfs/df_run1_ext.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dd794e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#——————————————————————————————————————\n",
    "# Load Dataframes for fast code running \n",
    "#——————————————————————————————————————\n",
    "\n",
    "\n",
    "lock3 = False\n",
    "if lock3==True:\n",
    "    df_mc = pd.read_csv('dfs/df_run1_mc.csv')\n",
    "    df_beam_on = pd.read_csv('dfs/df_run1_data.csv')\n",
    "    df_dirt = pd.read_csv('dfs/df_run1_dirt.csv')\n",
    "    df_ext = pd.read_csv('dfs/df_run1_ext.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3de568",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#————————————————————————————————————————————————————\n",
    "# Now apply selection and draw histo and show entries \n",
    "#————————————————————————————————————————————————————\n",
    "\n",
    "\n",
    "df_data1, df_ext1, df_mc1 = applyCuts('None', df_beam_on, df_ext, df_mc, True, POT_data=run1_pot_beam_on)\n",
    "df_data2, df_ext2, df_mc2 = applyCuts('recoVtxTrim', df_data1, df_ext1, df_mc1, True, POT_data=run1_pot_beam_on)\n",
    "df_data3, df_ext3, df_mc3 = applyCuts('fiducialVol', df_data2, df_ext2, df_mc2, True, POT_data=run1_pot_beam_on)\n",
    "df_data4, df_ext4, df_mc4 = applyCuts('genNuSelection', df_data3, df_ext3, df_mc3, True, POT_data=run1_pot_beam_on)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088ad976",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
